{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code will develop a Retrieval Augemented Generation (RAG) based chat bot using LangChain, PineCone and OpenAI with the following salient points\n",
    "\n",
    "Firstly, we will develop a chatbot which won't use RAG. Then we will convert this chatbot into a RAG based robot using Embeddings and Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import langchain.vectorstores as vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the OpenAI and Pinecone API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds_file = \"../credentials.json\"\n",
    "    \n",
    "with open(creds_file, 'r') as file:\n",
    "    creds_data = json.load(file)\n",
    "    openai_api_key = creds_data['OPENAI_API_KEY']\n",
    "    pinecone_api_key = creds_data['PINECONE_API_KEY']\n",
    "\n",
    "assert openai_api_key != None, \"\"\n",
    "assert pinecone_api_key != None, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the OpenAI Chat Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat  = ChatOpenAI(\n",
    "    openai_api_key = openai_api_key,\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the chat message for the robot in Langchain to chat with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I am great thank you, How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand String Theory.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mn27889/miniconda3/envs/rag-chatbot/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String theory is a theoretical framework in physics that attempts to reconcile general relativity and quantum mechanics. It posits that the fundamental building blocks of the universe are not particles, but tiny, vibrating strings. These strings can have different vibrational modes, which correspond to different particles and forces in the universe.\n",
      "\n",
      "One of the key ideas of string theory is that it requires more than the usual three spatial dimensions and one time dimension. In fact, string theory predicts the existence of extra dimensions beyond the familiar three dimensions of space and one dimension of time.\n",
      "\n",
      "There are several different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8xE8. These different versions are related through dualities, which suggest that they are actually different descriptions of the same underlying theory.\n",
      "\n",
      "String theory is a complex and mathematically sophisticated theory that has the potential to provide a unified description of all fundamental forces and particles in the universe. However, it is still a work in progress, and many aspects of the theory are still not fully understood.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant'),\n",
       " HumanMessage(content='Hi AI, how are you today?'),\n",
       " AIMessage(content='I am great thank you, How can I help you?'),\n",
       " HumanMessage(content=\"I'd like to understand String Theory.\"),\n",
       " AIMessage(content='String theory is a theoretical framework in physics that attempts to reconcile general relativity and quantum mechanics. It posits that the fundamental building blocks of the universe are not particles, but tiny, vibrating strings. These strings can have different vibrational modes, which correspond to different particles and forces in the universe.\\n\\nOne of the key ideas of string theory is that it requires more than the usual three spatial dimensions and one time dimension. In fact, string theory predicts the existence of extra dimensions beyond the familiar three dimensions of space and one dimension of time.\\n\\nThere are several different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8xE8. These different versions are related through dualities, which suggest that they are actually different descriptions of the same underlying theory.\\n\\nString theory is a complex and mathematically sophisticated theory that has the potential to provide a unified description of all fundamental forces and particles in the universe. However, it is still a work in progress, and many aspects of the theory are still not fully understood.', response_metadata={'token_usage': {'completion_tokens': 219, 'prompt_tokens': 52, 'total_tokens': 271}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c3856fd1-4bc9-4616-a9e3-929e272da142-0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"Why do physicists believe it can prduce a unified theory?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory has the potential to produce a unified theory because it has the ability to describe all fundamental forces and particles in a single, coherent framework. Here are some reasons why physicists see string theory as a promising candidate for a unified theory:\n",
      "\n",
      "1. **Incorporates Gravity**: Unlike quantum field theories, which struggle to incorporate gravity, string theory naturally includes gravity as one of the fundamental forces. This is important for achieving a unified theory that can describe all four fundamental forces (gravity, electromagnetism, weak nuclear force, and strong nuclear force) in a consistent manner.\n",
      "\n",
      "2. **Resolves Infinities**: String theory has the potential to resolve the mathematical infinities that arise in quantum field theories, particularly in the context of gravity. By replacing point-like particles with extended objects (strings), string theory avoids certain infinities that plague traditional quantum field theories.\n",
      "\n",
      "3. **Dualities**: String theory exhibits various dualities, such as T-duality and S-duality, which relate seemingly different versions of the theory to each other. These dualities suggest that different formulations of string theory are actually different descriptions of the same underlying theory. This hints at a deeper, more fundamental structure that could lead to a unified theory.\n",
      "\n",
      "4. **Extra Dimensions**: String theory naturally predicts the existence of extra spatial dimensions beyond the familiar three dimensions of space. These extra dimensions could potentially provide a framework for unifying the fundamental forces and particles in a higher-dimensional space.\n",
      "\n",
      "5. **Consistency**: String theory is a mathematically consistent framework that avoids certain paradoxes and inconsistencies that arise in other theories, such as quantum field theory. This consistency gives physicists confidence that string theory may indeed provide a unified description of the universe.\n",
      "\n",
      "While string theory has shown great promise in these aspects, it is important to note that it is still a theoretical framework and has not yet been definitively proven through experimental observation. Research in string theory is ongoing, and physicists are actively exploring its implications and predictions in the hope of uncovering a unified theory of fundamental physics.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant'),\n",
       " HumanMessage(content='Hi AI, how are you today?'),\n",
       " AIMessage(content='I am great thank you, How can I help you?'),\n",
       " HumanMessage(content=\"I'd like to understand String Theory.\"),\n",
       " AIMessage(content='String theory is a theoretical framework in physics that attempts to reconcile general relativity and quantum mechanics. It posits that the fundamental building blocks of the universe are not particles, but tiny, vibrating strings. These strings can have different vibrational modes, which correspond to different particles and forces in the universe.\\n\\nOne of the key ideas of string theory is that it requires more than the usual three spatial dimensions and one time dimension. In fact, string theory predicts the existence of extra dimensions beyond the familiar three dimensions of space and one dimension of time.\\n\\nThere are several different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8xE8. These different versions are related through dualities, which suggest that they are actually different descriptions of the same underlying theory.\\n\\nString theory is a complex and mathematically sophisticated theory that has the potential to provide a unified description of all fundamental forces and particles in the universe. However, it is still a work in progress, and many aspects of the theory are still not fully understood.', response_metadata={'token_usage': {'completion_tokens': 219, 'prompt_tokens': 52, 'total_tokens': 271}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c3856fd1-4bc9-4616-a9e3-929e272da142-0'),\n",
       " HumanMessage(content='Why do physicists believe it can prduce a unified theory?'),\n",
       " AIMessage(content='Physicists believe that string theory has the potential to produce a unified theory because it has the ability to describe all fundamental forces and particles in a single, coherent framework. Here are some reasons why physicists see string theory as a promising candidate for a unified theory:\\n\\n1. **Incorporates Gravity**: Unlike quantum field theories, which struggle to incorporate gravity, string theory naturally includes gravity as one of the fundamental forces. This is important for achieving a unified theory that can describe all four fundamental forces (gravity, electromagnetism, weak nuclear force, and strong nuclear force) in a consistent manner.\\n\\n2. **Resolves Infinities**: String theory has the potential to resolve the mathematical infinities that arise in quantum field theories, particularly in the context of gravity. By replacing point-like particles with extended objects (strings), string theory avoids certain infinities that plague traditional quantum field theories.\\n\\n3. **Dualities**: String theory exhibits various dualities, such as T-duality and S-duality, which relate seemingly different versions of the theory to each other. These dualities suggest that different formulations of string theory are actually different descriptions of the same underlying theory. This hints at a deeper, more fundamental structure that could lead to a unified theory.\\n\\n4. **Extra Dimensions**: String theory naturally predicts the existence of extra spatial dimensions beyond the familiar three dimensions of space. These extra dimensions could potentially provide a framework for unifying the fundamental forces and particles in a higher-dimensional space.\\n\\n5. **Consistency**: String theory is a mathematically consistent framework that avoids certain paradoxes and inconsistencies that arise in other theories, such as quantum field theory. This consistency gives physicists confidence that string theory may indeed provide a unified description of the universe.\\n\\nWhile string theory has shown great promise in these aspects, it is important to note that it is still a theoretical framework and has not yet been definitively proven through experimental observation. Research in string theory is ongoing, and physicists are actively exploring its implications and predictions in the hope of uncovering a unified theory of fundamental physics.', response_metadata={'token_usage': {'completion_tokens': 414, 'prompt_tokens': 291, 'total_tokens': 705}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d46b283c-28ce-44df-8170-6f2e65a806bb-0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we ask anything from LLM which the LLM does not know about, then it will ask us to provide more information about this topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"Why do you know about LLama2?\"\n",
    ")\n",
    "\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have information about LLama2. It seems like you may be referring to something specific or asking about a topic that I am not familiar with. If you can provide more context or details, I'd be happy to try to help or provide information on a related topic.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"Can you tell me more about the LLMChain in LangChain?\"\n",
    ")\n",
    "\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I am not familiar with the specific terms \"LLMChain\" or \"LangChain.\" It's possible that they are related to a specific project, technology, or concept that I may not have information about. If you can provide more context or details, I'd be happy to try to help or provide information on a related topic.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's provide this specific knowledge base in the context of our query to guide the LLM about a suitable answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmchain_information = [\n",
    "    \"A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\",\n",
    "    \"Chains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\",\n",
    "    \"LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\"\n",
    "]\n",
    "\n",
    "source_knowledge = \"\\n\".join(llmchain_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you tell me about the LLMChain in LangChain?\"\n",
    "\n",
    "augmented_query = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=augmented_query\n",
    ")\n",
    "\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLMChain in LangChain is a common type of chain within the LangChain framework for developing applications powered by language models. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. The LLMChain takes multiple input variables, utilizes the PromptTemplate to format them into a prompt, passes that prompt to the model for processing, and then uses the OutputParser (if provided) to parse the output of the LLM into a final format.\n",
      "\n",
      "In the context of LangChain, a chain refers to a sequence of modular components or other chains that are combined in a specific way to achieve a common use case. LangChain aims to enable the development of powerful and differentiated applications that go beyond just calling out to a language model via an API. These applications are designed to be data-aware, connecting language models to other sources of data, and agentic, allowing language models to interact with their environment.\n",
      "\n",
      "Overall, the LLMChain in LangChain plays a crucial role in processing input data, generating prompts, utilizing language models for processing, and parsing the output to create a final output format within the LangChain framework for developing advanced language model-powered applications.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the knowledgebase in PineCone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"jamescalam/llama-2-arxiv-papers-chunked\",\n",
    "    split = \"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doi': '1102.0183',\n",
       " 'chunk-id': '0',\n",
       " 'chunk': 'High-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nTechnical Report No. IDSIA-01-11\\nJanuary 2011\\nIDSIA / USI-SUPSI\\nDalle Molle Institute for Arti\\x0ccial Intelligence\\nGalleria 2, 6928 Manno, Switzerland\\nIDSIA is a joint institute of both University of Lugano (USI) and University of Applied Sciences of Southern Switzerland (SUPSI),\\nand was founded in 1988 by the Dalle Molle Foundation which promoted quality of life.\\nThis work was partially supported by the Swiss Commission for Technology and Innovation (CTI), Project n. 9688.1 IFF:\\nIntelligent Fill in Form.arXiv:1102.0183v1  [cs.AI]  1 Feb 2011\\nTechnical Report No. IDSIA-01-11 1\\nHigh-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nJanuary 2011\\nAbstract\\nWe present a fast, fully parameterizable GPU implementation of Convolutional Neural\\nNetwork variants. Our feature extractors are neither carefully designed nor pre-wired, but',\n",
       " 'id': '1102.0183',\n",
       " 'title': 'High-Performance Neural Networks for Visual Object Classification',\n",
       " 'summary': 'We present a fast, fully parameterizable GPU implementation of Convolutional\\nNeural Network variants. Our feature extractors are neither carefully designed\\nnor pre-wired, but rather learned in a supervised way. Our deep hierarchical\\narchitectures achieve the best published results on benchmarks for object\\nclassification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with\\nerror rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple\\nback-propagation perform better than more shallow ones. Learning is\\nsurprisingly rapid. NORB is completely trained within five epochs. Test error\\nrates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,\\nrespectively.',\n",
       " 'source': 'http://arxiv.org/pdf/1102.0183',\n",
       " 'authors': ['Dan C. Cireşan',\n",
       "  'Ueli Meier',\n",
       "  'Jonathan Masci',\n",
       "  'Luca M. Gambardella',\n",
       "  'Jürgen Schmidhuber'],\n",
       " 'categories': ['cs.AI', 'cs.NE'],\n",
       " 'comment': '12 pages, 2 figures, 5 tables',\n",
       " 'journal_ref': None,\n",
       " 'primary_category': 'cs.AI',\n",
       " 'published': '20110201',\n",
       " 'updated': '20110201',\n",
       " 'references': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the PineCone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure client\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# configure serverless spec\n",
    "spec = ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "\n",
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for and delete index if already exists\n",
    "index_name = 'rag-chatbot-raw'\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# we create a new index\n",
    "pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,  # dimensionality of text-embedding-ada-002\n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "\n",
    "# Wait until the index is ready\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 4838}},\n",
       " 'total_vector_count': 4838}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiating the Embedding model to create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAIEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m(api_key\u001b[38;5;241m=\u001b[39mopenai_api_key, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAIEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embed_model = OpenAIEmbeddings(api_key=openai_api_key, model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"this is the first chunk of the text\",\n",
    "    \"then anothe second chunk of the text is here\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = embed_model.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res), len(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting the embeddings and metadata to PineCone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:10<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "data = dataset.to_pandas()\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    \n",
    "    batch = data.iloc[i:i_end]\n",
    "    \n",
    "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i,x in batch.iterrows()]\n",
    "    \n",
    "    texts = [x['chunk'] for _, x in batch.iterrows()]\n",
    "    \n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    \n",
    "    metadata = [\n",
    "        {\n",
    "            'text': x['chunk'],\n",
    "            'source': x['source'],\n",
    "            'title': x['title']\n",
    "        } for i,x in batch.iterrows()\n",
    "    ]\n",
    "    \n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 4838}},\n",
       " 'total_vector_count': 4838}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval Augmented Generation using Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mn27889/miniconda3/envs/rag-chatbot/lib/python3.11/site-packages/langchain_community/vectorstores/pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_field = \"text\" # the metadata field that contains our text\n",
    "vectorstore = vectorstore.Pinecone(index, embed_model.embed_query, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}, page_content='Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom\\x03\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur ﬁne-tuned LLMs, called L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosedsource models. We provide a detailed description of our approach to ﬁne-tuning and safety'),\n",
       " Document(metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}, page_content='asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see'),\n",
       " Document(metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}, page_content='Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and eﬃcient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is so special about Llama 2\"\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # Get Top 3 results\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    \n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "    \n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "    \n",
    "    Query: {query}\"\"\"\n",
    "    \n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_query = augment_prompt(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I am great thank you, How can I help you?\"),\n",
    "    HumanMessage(content=final_query)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mn27889/miniconda3/envs/rag-chatbot/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. The fine-tuned LLMs, specifically L/l.sc/a.sc/m.sc/a.sc/two.taboldstyle-C/h.sc/a.sc/t.sc, are optimized for dialogue use cases. In benchmarks tested, these models outperform open-source chat models and even demonstrate potential as substitutes for closed-source models based on human evaluations for helpfulness and safety. The fine-tuning and safety approaches taken with Llama 2 are detailed and aim to enhance usability and safety without the significant costs and lack of transparency often associated with closed-source models.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
